
import PyPDF2
from PIL import Image

from matplotlib import pyplot as plt
import numpy as np
import sys
from os import path
import warnings
warnings.filterwarnings("ignore")

def extract_images_from_pdf(filename, num_pages, dest_dir):
    number = 0

    def recurse(page, xObject):
        global number

        xObject = xObject['/Resources']['/XObject'].getObject()

        for obj in xObject:

            if xObject[obj]['/Subtype'] == '/Image':
                size = (xObject[obj]['/Width'], xObject[obj]['/Height'])
                data = xObject[obj].getData()

                if xObject[obj]['/ColorSpace'] == '/DeviceRGB':
                    mode = "RGB"
                else:
                    # todo - currently manually set to RGB
                    mode = "RGB"

                imagename = "%s - p. %s"%(obj[1:], p)

                if xObject[obj]['/Filter'] == '/FlateDecode':
                    img = Image.frombytes(mode, size, data)
                    img.save(dest_dir + imagename + ".png")
                    number += 1
                    
                # todo
#                 elif xObject[obj]['/Filter'] == '/DCTDecode':
#                     img = open(imagename + ".jpg", "wb")
#                     img.write(data)
#                     img.close()
#                     number += 1
#                 elif xObject[obj]['/Filter'] == '/JPXDecode':
#                     img = open(imagename + ".jp2", "wb")
#                     img.write(data)
#                     img.close()
#                     number += 1
            else:
                recurse(page, xObject[obj])

    abspath = path.abspath(filename)
    pdf_file = PyPDF2.PdfFileReader(open(filename, "rb"))

    for p in range(num_pages):    
        page0 = pdf_file.getPage(p-1)
        recurse(p, page0)

    print('%s extracted images'% number)
    
    
extract_images_from_pdf('../data/GelsNov2016.pdf', 162, '../data/gels_nov_2016/')

from __future__ import print_function

import numpy as np
from matplotlib import pyplot as plt

from skimage import data
from skimage.util import img_as_float
from skimage.feature import (corner_harris, corner_subpix, corner_peaks,
                             plot_matches)
from skimage.transform import warp, AffineTransform
from skimage.exposure import rescale_intensity
from skimage.color import rgb2gray
from skimage.measure import ransac


from IPython import embed
embed()


img_1 = data.imread('../data/gels_nov_2016/Im1 - p. 1.png', flatten=True)
img_2 = data.imread('../data/gels_nov_2016/Im2 - p. 2.png', flatten=True)

print(img_1.shape)
print(img_2.shape)

# plt.imshow(img_1)
# plt.show()

# generate synthetic checkerboard image and add gradient for the later matching
checkerboard = img_as_float(data.checkerboard())
img_orig = np.zeros(list(checkerboard.shape) + [3])
img_orig[..., 0] = checkerboard
gradient_r, gradient_c = (np.mgrid[0:img_orig.shape[0],
                                   0:img_orig.shape[1]]
                          / float(img_orig.shape[0]))
img_orig[..., 1] = gradient_r
img_orig[..., 2] = gradient_c
img_orig = rescale_intensity(img_orig)
img_orig_gray = rgb2gray(img_orig)

# warp synthetic image
tform = AffineTransform(scale=(0.9, 0.9), rotation=0.2, translation=(20, -10))
img_warped = warp(img_orig, tform.inverse, output_shape=(200, 200))
img_warped_gray = rgb2gray(img_warped)


from skimage import transform
shape = (1276, 2100)
img_1 = transform.resize(img_1, output_shape=shape)
img_2 = transform.resize(img_2, output_shape=shape)






# extract corners using Harris' corner measure
coords_1 = corner_peaks(corner_harris(img_1), threshold_rel=0.001,
                           min_distance=5)
coords_2 = corner_peaks(corner_harris(img_2),
                             threshold_rel=0.001, min_distance=5)

# determine sub-pixel corner position
coords_1_subpix = corner_subpix(img_1, coords_1, window_size=9)
coords_2_subpix = corner_subpix(img_2, coords_2,
                                     window_size=9)


def gaussian_weights(window_ext, sigma=1):
    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]
    g = np.zeros(y.shape, dtype=np.double)
    g[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))
    g /= 2 * np.pi * sigma * sigma
    return g


def match_corner(coord, window_ext=5):
    r, c = np.round(coord).astype(np.intp)
    print(r, c)
    window_1 = img_1[r-window_ext:r+window_ext+1,
                           c-window_ext:c+window_ext+1]#, :]

    # weight pixels depending on distance to center pixel
    weights = gaussian_weights(window_ext, 3)
#     weights = np.dstack((weights, weights, weights))

    # compute sum of squared differences to all corners in warped image
    SSDs = []
    for cr, cc in coords_2:
        window_2 = img_2[cr-window_ext:cr+window_ext+1,
                                   cc-window_ext:cc+window_ext+1]#, :]
        
        print(window_1.shape, window_2.shape, weights.shape)
        thing = (window_1 - window_2)**2
        print(thing.shape)
        
        SSD = np.sum(weights * (window_1 - window_2)**2)
        SSDs.append(SSD)

    # use corner with minimum SSD as correspondence
    min_idx = np.argmin(SSDs)
    return coords_2_subpix[min_idx]


# find correspondences using simple weighted sum of squared differences
src = []
dst = []
for coord in coords_1_subpix:
    src.append(coord)
    dst.append(match_corner(coord))
src = np.array(src)
dst = np.array(dst)


# estimate affine transform model using all coordinates
model = AffineTransform()
model.estimate(src, dst)

# robustly estimate affine transform model with RANSAC
model_robust, inliers = ransac((src, dst), AffineTransform, min_samples=3,
                               residual_threshold=2, max_trials=100)
outliers = inliers == False


# compare "true" and estimated transform parameters
print(tform.scale, tform.translation, tform.rotation)
print(model.scale, model.translation, model.rotation)
print(model_robust.scale, model_robust.translation, model_robust.rotation)

# visualize correspondence
fig, ax = plt.subplots(nrows=2, ncols=1)

plt.gray()

inlier_idxs = np.nonzero(inliers)[0]
plot_matches(ax[0], img_1, img_2, src, dst,
             np.column_stack((inlier_idxs, inlier_idxs)), matches_color='b')
ax[0].axis('off')
ax[0].set_title('Correct correspondences')

outlier_idxs = np.nonzero(outliers)[0]
plot_matches(ax[1], img_1, img_2, src, dst,
             np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')
ax[1].axis('off')
ax[1].set_title('Faulty correspondences')

# plt.show()


