{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New PDF Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(filename, num_pages, dest_dir):\n",
    "    number = 0\n",
    "\n",
    "    def recurse(page, xObject):\n",
    "        global number\n",
    "\n",
    "        xObject = xObject['/Resources']['/XObject'].getObject()\n",
    "\n",
    "        for obj in xObject:\n",
    "\n",
    "            if xObject[obj]['/Subtype'] == '/Image':\n",
    "                size = (xObject[obj]['/Width'], xObject[obj]['/Height'])\n",
    "                data = xObject[obj].getData()\n",
    "\n",
    "                if xObject[obj]['/ColorSpace'] == '/DeviceRGB':\n",
    "                    mode = \"RGB\"\n",
    "                else:\n",
    "                    # todo - currently manually set to RGB\n",
    "                    mode = \"RGB\"\n",
    "\n",
    "                imagename = \"%s - p. %s\"%(obj[1:], p)\n",
    "\n",
    "                if xObject[obj]['/Filter'] == '/FlateDecode':\n",
    "                    img = Image.frombytes(mode, size, data)\n",
    "                    img.save(dest_dir + imagename + \".png\")\n",
    "                    number += 1\n",
    "                    \n",
    "                # todo\n",
    "#                 elif xObject[obj]['/Filter'] == '/DCTDecode':\n",
    "#                     img = open(imagename + \".jpg\", \"wb\")\n",
    "#                     img.write(data)\n",
    "#                     img.close()\n",
    "#                     number += 1\n",
    "#                 elif xObject[obj]['/Filter'] == '/JPXDecode':\n",
    "#                     img = open(imagename + \".jp2\", \"wb\")\n",
    "#                     img.write(data)\n",
    "#                     img.close()\n",
    "#                     number += 1\n",
    "            else:\n",
    "                recurse(page, xObject[obj])\n",
    "\n",
    "    abspath = path.abspath(filename)\n",
    "    pdf_file = PyPDF2.PdfFileReader(open(filename, \"rb\"))\n",
    "\n",
    "    for p in range(num_pages):    \n",
    "        page0 = pdf_file.getPage(p-1)\n",
    "        recurse(p, page0)\n",
    "\n",
    "    print('%s extracted images'% number)\n",
    "    \n",
    "    \n",
    "extract_images_from_pdf('../data/GelsNov2016.pdf', 162, '../data/gels_nov_2016/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Type I gels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import data\n",
    "from skimage import transform\n",
    "from skimage.util import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "\n",
    "imgs_blue = []\n",
    "imgs_blue_idx = [1,6,7,12,21,22,41,42,51,52,56,83,84,89,90,96,97,106,123,131,136,152,153,156,157]\n",
    "\n",
    "shape = (1276, 2100)\n",
    "\n",
    "for idx in imgs_blue_idx:\n",
    "    cur_im = data.imread('../data/gels_nov_2016/Im{} - p. {}.png'.format(idx, idx), flatten=True)\n",
    "    \n",
    "    cur_im = img_as_float(cur_im)\n",
    "    cur_im = rescale_intensity(cur_im)\n",
    "    cur_im = rgb2gray(cur_im)\n",
    "    \n",
    "    cur_im = transform.resize(cur_im, output_shape=shape) # todo\n",
    "    \n",
    "    imgs_blue.append(cur_im)\n",
    "    \n",
    "len(imgs_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Alignment - ORB + RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.feature import ORB, match_descriptors\n",
    "from skimage.transform import ProjectiveTransform, AffineTransform, EuclideanTransform # !!!!!!!!!!\n",
    "from skimage.measure import ransac\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import warp\n",
    "from skimage.transform import SimilarityTransform\n",
    "\n",
    "\n",
    "img_1 = imgs_blue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_alpha(image, background=-1):\n",
    "    \"\"\"Add an alpha layer to the image.\n",
    "\n",
    "    The alpha layer is set to 1 for foreground\n",
    "    and 0 for background.\n",
    "    \"\"\"\n",
    "    rgb = gray2rgb(image)\n",
    "    alpha = (image != background)\n",
    "    return np.dstack((rgb, alpha))\n",
    "\n",
    "\n",
    "def align_images(img_1, img_2):\n",
    "    orb = ORB(n_keypoints=500, fast_threshold=0.05)\n",
    "\n",
    "    orb.detect_and_extract(img_1)\n",
    "    keypoints1 = orb.keypoints\n",
    "    descriptors1 = orb.descriptors\n",
    "\n",
    "    orb.detect_and_extract(img_2)\n",
    "    keypoints2 = orb.keypoints\n",
    "    descriptors2 = orb.descriptors\n",
    "\n",
    "    matches12 = match_descriptors(descriptors1,\n",
    "                                  descriptors2,\n",
    "                                  cross_check=True)\n",
    "\n",
    "    # Select keypoints from the source (image to be\n",
    "    # registered) and target (reference image).\n",
    "    src = keypoints2[matches12[:, 1]][:, ::-1]\n",
    "    dst = keypoints1[matches12[:, 0]][:, ::-1]\n",
    "\n",
    "    model_robust, inliers = ransac((src, dst), EuclideanTransform,\n",
    "               min_samples=4, residual_threshold=2)\n",
    "\n",
    "    r, c = img_1.shape[:2]\n",
    "\n",
    "    # Note that transformations take coordinates in\n",
    "    # (x, y) format, not (row, column), in order to be\n",
    "    # consistent with most literature.\n",
    "    corners = np.array([[0, 0],\n",
    "                        [0, r],\n",
    "                        [c, 0],\n",
    "                        [c, r]])\n",
    "\n",
    "    # Warp the image corners to their new positions.\n",
    "    warped_corners = model_robust(corners)\n",
    "\n",
    "    # Find the extents of both the reference image and\n",
    "    # the warped target image.\n",
    "    all_corners = np.vstack((warped_corners, corners))\n",
    "\n",
    "    corner_min = np.min(all_corners, axis=0)\n",
    "    corner_max = np.max(all_corners, axis=0)\n",
    "\n",
    "    output_shape = (corner_max - corner_min)\n",
    "    output_shape += np.abs(corner_min)\n",
    "    output_shape = output_shape[::-1].astype(int) # todo - check\n",
    "    \n",
    "    if np.min(output_shape) < 0: # todo - means no alignment found?\n",
    "        return None\n",
    "\n",
    "    offset = SimilarityTransform(translation=-corner_min)\n",
    "    \n",
    "    image0_ = warp(img_1, offset.inverse,\n",
    "                   output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image1_ = warp(img_2, (offset + model_robust).inverse,\n",
    "                   output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image0_alpha = add_alpha(image0_)\n",
    "    image1_alpha = add_alpha(image1_)\n",
    "\n",
    "    merged = (image0_alpha + image1_alpha)\n",
    "    alpha = merged[..., 3]\n",
    "\n",
    "    # The summed alpha layers give us an indication of\n",
    "    # how many images were combined to make up each\n",
    "    # pixel. Divide by the number of images to get\n",
    "    # an average.\n",
    "    merged /= np.maximum(alpha, 1)[..., np.newaxis]\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merges_with_one = [align_images(img_1, x) for x in imgs_blue]\n",
    "\n",
    "for i, m in enumerate(merges_with_one):\n",
    "    if m != None:\n",
    "        orig_idx = imgs_blue_idx[i]\n",
    "        result_filename = 'merged_{}.jpg'.format(orig_idx)\n",
    "        matplotlib.image.imsave('./alignments/' + result_filename, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gels-analysis",
   "language": "python",
   "name": "gels-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
