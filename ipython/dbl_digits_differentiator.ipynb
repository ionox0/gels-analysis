{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import scipy\n",
    "import pprint\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "from skimage.feature import hog\n",
    "from skimage.morphology import square, disk\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat\n",
    "from skimage.morphology import black_tophat, skeletonize, convex_hull_image\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from skimage import data\n",
    "import keras\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_things(things, labels):\n",
    "    count = len(things)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    for i, thing in enumerate(things):\n",
    "        cols = 10\n",
    "        rows = int(count / cols) + 1\n",
    "        ax = plt.subplot(rows, cols, 1 + i)\n",
    "        \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title(labels[i])\n",
    "\n",
    "        plt.imshow(thing)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "data = mnist.data\n",
    "target = mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_labels = np.zeros(data.shape[0])\n",
    "single_labels = to_categorical(single_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def random_combination(iterable, r):\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    indices = sorted(random.sample(xrange(n), r))\n",
    "    return tuple(pool[i] for i in indices)\n",
    "\n",
    "def remove_border(img):\n",
    "    where = np.where(img > 0)\n",
    "    y1 = np.min(where[0])\n",
    "    y2 = np.max(where[0])\n",
    "    x1 = np.min(where[1])\n",
    "    x2 = np.max(where[1])\n",
    "    crop = img[y1:y2 , x1:x2]\n",
    "    return crop\n",
    "\n",
    "n_samples = 1000000\n",
    "combs = []\n",
    "combs_labels = []\n",
    "data_w_labels = zip(data, target)\n",
    "random.shuffle(data_w_labels)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    comb = random_combination(data_w_labels, 2)\n",
    "    \n",
    "    first_digit = comb[0][0].reshape((28, 28))\n",
    "    second_digit = comb[1][0].reshape((28, 28))\n",
    "\n",
    "#     thresh = threshold_otsu(first_digit)\n",
    "#     first_digit = (first_digit > thresh).astype(np.uint8)\n",
    "    \n",
    "#     thresh = threshold_otsu(second_digit)\n",
    "#     second_digit = (second_digit > thresh).astype(np.uint8)\n",
    "    \n",
    "    first_mod = remove_border(first_digit)\n",
    "    second_mod = remove_border(second_digit)\n",
    "    \n",
    "    # Make sure height diff is divisible by 2\n",
    "    if not (first_mod.shape[0] % 2 == 0):\n",
    "        first_mod = np.vstack([first_mod, np.zeros((1, first_mod.shape[1]))])\n",
    "    if not (second_mod.shape[0] % 2 == 0):\n",
    "        second_mod = np.vstack([second_mod, np.zeros((1, second_mod.shape[1]))])\n",
    "    \n",
    "    height_diff = first_mod.shape[0] - second_mod.shape[0]\n",
    "    \n",
    "    if height_diff < 0:\n",
    "        padding = int(-height_diff / 2.0)\n",
    "        thepad = np.zeros((padding, first_mod.shape[1]))\n",
    "        first_mod = np.vstack([first_mod, thepad])\n",
    "        first_mod = np.vstack([thepad, first_mod])\n",
    "    elif height_diff > 0:\n",
    "        padding = int(height_diff / 2.0)\n",
    "        thepad = np.zeros((padding, second_mod.shape[1]))\n",
    "        second_mod = np.vstack([second_mod, thepad])\n",
    "        second_mod = np.vstack([thepad, second_mod])\n",
    "    \n",
    "    # Align width\n",
    "    overlap = 1\n",
    "    \n",
    "    height = first_mod.shape[0]\n",
    "    width_1 = first_mod.shape[1]\n",
    "    width_2 = second_mod.shape[1]\n",
    "    \n",
    "    padding = np.zeros((height, width_2 - overlap))\n",
    "    first_mod = np.hstack([first_mod, padding])\n",
    "    padding = np.zeros((height, width_1 - overlap))\n",
    "    second_mod = np.hstack([padding, second_mod])\n",
    "    \n",
    "    overlapped = first_mod.astype(np.uint64) + second_mod.astype(np.uint64)\n",
    "    overlapped = np.clip(overlapped, 0, 255).astype(np.uint8)\n",
    "    padded = np.pad(overlapped, (5, 5), 'constant', constant_values=(0, 0))  \n",
    "    \n",
    "#     binary = (padded > 0).astype(np.uint8)\n",
    "    combs.append(padded)\n",
    "    \n",
    "    label = int(  str(int(comb[0][1])) + str(int(comb[1][1]))  )\n",
    "    combs_labels.append( 1 )\n",
    "    \n",
    "# combs = np.array(combs)\n",
    "combs_labels = np.array(combs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combs_reshaped = [cv2.resize(x, (38, 28)) for x in combs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 50\n",
    "plot_things(combs_reshaped[i:i + 50], combs_labels[i:i + 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the features and labels\n",
    "combs_np = np.array(combs_reshaped)\n",
    "dbl_features = np.expand_dims(combs_np.reshape(1000000, 28, 38), axis=3)\n",
    "dbl_labels = to_categorical(combs_labels)\n",
    "\n",
    "dbl_single = np.concat([data, dbl_features], axis=0)\n",
    "dbl_single_labels = np.concat([single_labels, dbl_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28, 38, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 7\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "\n",
    "history_bn = model.fit(\n",
    "    features,\n",
    "    labels,\n",
    "    validation_split=0.05,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[earlyStopping], \n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Save the classifier\n",
    "model.save(filepath='./double_digits_cnn_nonbinary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
