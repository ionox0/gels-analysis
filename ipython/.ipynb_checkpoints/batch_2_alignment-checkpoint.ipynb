{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New PDF Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(filename, num_pages, dest_dir):\n",
    "    number = 0\n",
    "\n",
    "    def recurse(page, xObject):\n",
    "        global number\n",
    "\n",
    "        xObject = xObject['/Resources']['/XObject'].getObject()\n",
    "\n",
    "        for obj in xObject:\n",
    "\n",
    "            if xObject[obj]['/Subtype'] == '/Image':\n",
    "                size = (xObject[obj]['/Width'], xObject[obj]['/Height'])\n",
    "                data = xObject[obj].getData()\n",
    "\n",
    "                if xObject[obj]['/ColorSpace'] == '/DeviceRGB':\n",
    "                    mode = \"RGB\"\n",
    "                else:\n",
    "                    # todo - currently manually set to RGB\n",
    "                    mode = \"RGB\"\n",
    "\n",
    "                imagename = \"%s - p. %s\"%(obj[1:], p)\n",
    "\n",
    "                if xObject[obj]['/Filter'] == '/FlateDecode':\n",
    "                    img = Image.frombytes(mode, size, data)\n",
    "                    img.save(dest_dir + imagename + \".png\")\n",
    "                    number += 1\n",
    "                    \n",
    "                # todo\n",
    "#                 elif xObject[obj]['/Filter'] == '/DCTDecode':\n",
    "#                     img = open(imagename + \".jpg\", \"wb\")\n",
    "#                     img.write(data)\n",
    "#                     img.close()\n",
    "#                     number += 1\n",
    "#                 elif xObject[obj]['/Filter'] == '/JPXDecode':\n",
    "#                     img = open(imagename + \".jp2\", \"wb\")\n",
    "#                     img.write(data)\n",
    "#                     img.close()\n",
    "#                     number += 1\n",
    "            else:\n",
    "                recurse(page, xObject[obj])\n",
    "\n",
    "    abspath = path.abspath(filename)\n",
    "    pdf_file = PyPDF2.PdfFileReader(open(filename, \"rb\"))\n",
    "\n",
    "    for p in range(num_pages):    \n",
    "        page0 = pdf_file.getPage(p-1)\n",
    "        recurse(p, page0)\n",
    "\n",
    "    print('%s extracted images'% number)\n",
    "    \n",
    "    \n",
    "extract_images_from_pdf('../data/GelsNov2016.pdf', 162, '../data/gels_nov_2016/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Type I gels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import data\n",
    "from skimage import transform\n",
    "from skimage.util import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "\n",
    "imgs_blue = []\n",
    "imgs_blue_idx = [1,6,7,12,21,22,41,42,51,52,56,83,84,89,90,96,97,106,123,131,136,152,153,156,157]\n",
    "\n",
    "shape = (1276, 2100)\n",
    "\n",
    "for idx in imgs_blue_idx:\n",
    "    cur_im = data.imread('../data/gels_nov_2016/Im{} - p. {}.png'.format(idx, idx), flatten=True)\n",
    "    \n",
    "    cur_im = img_as_float(cur_im)\n",
    "    cur_im = rescale_intensity(cur_im)\n",
    "    cur_im = rgb2gray(cur_im)\n",
    "    \n",
    "    cur_im = transform.resize(cur_im, output_shape=shape) # todo\n",
    "    \n",
    "    imgs_blue.append(cur_im)\n",
    "    \n",
    "len(imgs_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Alignment - Corners Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9, 0.9) [ 20. -10.] 0.2\n",
      "(4.9003118463690765, 0.4445991282964866) [ -309.07830055  1258.74134548] -0.523760968806\n",
      "(0.6655485208340479, 0.001163698050239835) [   13.58821725  1478.97683746] -0.690998214792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianjohnson/.virtualenvs/gels-analysis/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage.feature import (corner_harris, corner_subpix, corner_peaks,\n",
    "                             plot_matches)\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.measure import ransac\n",
    "\n",
    "\n",
    "# extract corners using Harris' corner measure\n",
    "coords_1 = corner_peaks(corner_harris(img_1), threshold_rel=0.001,\n",
    "                           min_distance=5)\n",
    "\n",
    "coords_2 = corner_peaks(corner_harris(img_2),\n",
    "                             threshold_rel=0.001, min_distance=5)\n",
    "\n",
    "\n",
    "# determine sub-pixel corner position\n",
    "coords_1_subpix = corner_subpix(img_1, coords_1, window_size=9)\n",
    "coords_2_subpix = corner_subpix(img_2, coords_2,\n",
    "                                     window_size=9)\n",
    "\n",
    "\n",
    "def gaussian_weights(window_ext, sigma=1):\n",
    "    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]\n",
    "    g = np.zeros(y.shape, dtype=np.double)\n",
    "    g[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))\n",
    "    g /= 2 * np.pi * sigma * sigma\n",
    "    return g\n",
    "\n",
    "\n",
    "def match_corner(coord, window_ext=3):\n",
    "#     print(\"coord: \", coord)\n",
    "    r, c = np.round(coord).astype(np.intp)\n",
    "#     print(r, c)\n",
    "    window_1 = img_1[r-window_ext:r+window_ext+1,\n",
    "                           c-window_ext:c+window_ext+1]#, :]\n",
    "    \n",
    "    # weight pixels depending on distance to center pixel\n",
    "    weights = gaussian_weights(window_ext, 3)\n",
    "#     weights = np.dstack((weights, weights, weights))\n",
    "\n",
    "    # compute sum of squared differences to all corners in warped image\n",
    "    SSDs = []\n",
    "    for cr, cc in coords_2:\n",
    "        window_2 = img_2[cr-window_ext:cr+window_ext+1,\n",
    "                                   cc-window_ext:cc+window_ext+1]#, :]\n",
    "        \n",
    "        SSD = np.sum(weights * (window_1 - window_2)**2)\n",
    "        SSDs.append(SSD)\n",
    "\n",
    "    # use corner with minimum SSD as correspondence\n",
    "    min_idx = np.argmin(SSDs)\n",
    "    return coords_2_subpix[min_idx]\n",
    "\n",
    "\n",
    "# find correspondences using simple weighted sum of squared differences\n",
    "src = []\n",
    "dst = []\n",
    "for coord in coords_1_subpix:\n",
    "#     print(coord)\n",
    "    if np.isnan(coord).any():\n",
    "        continue\n",
    "        \n",
    "    coord_match = match_corner(coord)\n",
    "    if np.isnan(coord_match).any():\n",
    "        continue\n",
    "        \n",
    "    src.append(coord)\n",
    "    dst.append(coord_match)\n",
    "src = np.array(src)\n",
    "dst = np.array(dst)\n",
    "\n",
    "# estimate affine transform model using all coordinates\n",
    "model = AffineTransform()\n",
    "model.estimate(src, dst)\n",
    "\n",
    "# robustly estimate affine transform model with RANSAC\n",
    "model_robust, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n",
    "                               residual_threshold=2, max_trials=100)\n",
    "outliers = inliers == False\n",
    "\n",
    "\n",
    "# compare \"true\" and estimated transform parameters\n",
    "print(tform.scale, tform.translation, tform.rotation)\n",
    "print(model.scale, model.translation, model.rotation)\n",
    "print(model_robust.scale, model_robust.translation, model_robust.rotation)\n",
    "\n",
    "# visualize correspondence\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "inlier_idxs = np.nonzero(inliers)[0]\n",
    "plot_matches(ax[0], img_1, img_2, src, dst,\n",
    "             np.column_stack((inlier_idxs, inlier_idxs)), matches_color='b')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Correct correspondences')\n",
    "\n",
    "outlier_idxs = np.nonzero(outliers)[0]\n",
    "plot_matches(ax[1], img_1, img_2, src, dst,\n",
    "             np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Faulty correspondences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Alignment - ORB + RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.feature import ORB, match_descriptors\n",
    "from skimage.transform import ProjectiveTransform, AffineTransform, EuclideanTransform # !!!!!!!!!!\n",
    "from skimage.measure import ransac\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import warp\n",
    "from skimage.transform import SimilarityTransform\n",
    "\n",
    "\n",
    "img_1 = imgs_blue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def align_images(img_1, img_2, i):\n",
    "    orb = ORB(n_keypoints=500, fast_threshold=0.05)\n",
    "\n",
    "    orb.detect_and_extract(img_1)\n",
    "    keypoints1 = orb.keypoints\n",
    "    descriptors1 = orb.descriptors\n",
    "\n",
    "    orb.detect_and_extract(img_2)\n",
    "    keypoints2 = orb.keypoints\n",
    "    descriptors2 = orb.descriptors\n",
    "\n",
    "    matches12 = match_descriptors(descriptors1,\n",
    "                                  descriptors2,\n",
    "                                  cross_check=True)\n",
    "\n",
    "    # Select keypoints from the source (image to be\n",
    "    # registered) and target (reference image).\n",
    "    src = keypoints2[matches12[:, 1]][:, ::-1].astype(int)\n",
    "    dst = keypoints1[matches12[:, 0]][:, ::-1].astype(int)\n",
    "\n",
    "    model_robust, inliers = \\\n",
    "        ransac((src, dst), EuclideanTransform,\n",
    "               min_samples=4, residual_threshold=2)\n",
    "\n",
    "    r, c = img_1.shape[:2]\n",
    "\n",
    "    # Note that transformations take coordinates in\n",
    "    # (x, y) format, not (row, column), in order to be\n",
    "    # consistent with most literature.\n",
    "    corners = np.array([[0, 0],\n",
    "                        [0, r],\n",
    "                        [c, 0],\n",
    "                        [c, r]])\n",
    "\n",
    "    # Warp the image corners to their new positions.\n",
    "    warped_corners = model_robust(corners)\n",
    "\n",
    "    # Find the extents of both the reference image and\n",
    "    # the warped target image.\n",
    "    all_corners = np.vstack((warped_corners, corners))\n",
    "\n",
    "    corner_min = np.min(all_corners, axis=0)\n",
    "    corner_max = np.max(all_corners, axis=0)\n",
    "\n",
    "    output_shape = (corner_max - corner_min)\n",
    "    output_shape += np.abs(corner_min)\n",
    "    output_shape = output_shape[::-1].astype(int) # todo - check\n",
    "    \n",
    "#     from IPython import embed\n",
    "#     embed()\n",
    "\n",
    "    offset = SimilarityTransform(translation=-corner_min)\n",
    "    \n",
    "    image0_ = warp(img_1, offset.inverse,\n",
    "                   output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image1_ = warp(img_2, (offset + model_robust).inverse,\n",
    "                   output_shape=output_shape, cval=-1)\n",
    "\n",
    "\n",
    "    def add_alpha(image, background=-1):\n",
    "        \"\"\"Add an alpha layer to the image.\n",
    "\n",
    "        The alpha layer is set to 1 for foreground\n",
    "        and 0 for background.\n",
    "        \"\"\"\n",
    "        rgb = gray2rgb(image)\n",
    "        alpha = (image != background)\n",
    "        return np.dstack((rgb, alpha))\n",
    "\n",
    "    image0_alpha = add_alpha(image0_)\n",
    "    image1_alpha = add_alpha(image1_)\n",
    "\n",
    "    merged = (image0_alpha + image1_alpha)\n",
    "    alpha = merged[..., 3]\n",
    "\n",
    "    # The summed alpha layers give us an indication of\n",
    "    # how many images were combined to make up each\n",
    "    # pixel. Divide by the number of images to get\n",
    "    # an average.\n",
    "    merged /= np.maximum(alpha, 1)[..., np.newaxis]\n",
    "    \n",
    "    result_filename = 'merged_{}.jpg'.format(i + 8)\n",
    "    matplotlib.image.imsave(result_filename, merged)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.13 (default, Dec 18 2016, 07:03:34) \n",
      "Type \"copyright\", \"credits\" or \"license\" for more information.\n",
      "\n",
      "IPython 5.3.0 -- An enhanced Interactive Python.\n",
      "?         -> Introduction and overview of IPython's features.\n",
      "%quickref -> Quick reference.\n",
      "help      -> Python's own help system.\n",
      "object?   -> Details about 'object', use 'object??' for extra details.\n",
      "\n",
      "In [1]: output_shape\n",
      "Out[1]: array([-9223372036854775808, -9223372036854775808])\n",
      "\n",
      "In [2]: corner_min\n",
      "Out[2]: array([ nan,  nan])\n",
      "\n",
      "In [3]: corner_max\n",
      "Out[3]: array([ nan,  nan])\n",
      "\n",
      "In [4]: warped_corners\n",
      "Out[4]: \n",
      "array([[ nan,  nan],\n",
      "       [ nan,  nan],\n",
      "       [ nan,  nan],\n",
      "       [ nan,  nan]])\n",
      "\n",
      "In [5]: corners\n",
      "Out[5]: \n",
      "array([[   0,    0],\n",
      "       [   0, 1276],\n",
      "       [2100,    0],\n",
      "       [2100, 1276]])\n",
      "\n",
      "In [6]: i\n",
      "Out[6]: 0\n",
      "\n",
      "In [7]: plt\n",
      "Out[7]: <module 'matplotlib.pyplot' from '/Users/ianjohnson/.virtualenvs/gels-analysis/lib/python2.7/site-packages/matplotlib/pyplot.pyc'>\n",
      "\n",
      "In [8]: plt.imshow(img_1)\n",
      "Out[8]: <matplotlib.image.AxesImage at 0x11d3a3390>\n",
      "\n",
      "In [9]: plt.show()\n",
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n",
      "\n",
      "\n",
      "In [10]: plt.imshow(img_2)\n",
      "Out[10]: <matplotlib.image.AxesImage at 0x1149058d0>\n",
      "\n",
      "In [11]: plt.show()\n",
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n",
      "\n",
      "\n",
      "In [12]: len(inliers)\n",
      "Out[12]: 112\n",
      "\n",
      "In [13]: model_robust(corners)\n",
      "Out[13]: \n",
      "array([[ nan,  nan],\n",
      "       [ nan,  nan],\n",
      "       [ nan,  nan],\n",
      "       [ nan,  nan]])\n",
      "\n",
      "In [14]: corners\n",
      "Out[14]: \n",
      "array([[   0,    0],\n",
      "       [   0, 1276],\n",
      "       [2100,    0],\n",
      "       [2100, 1276]])\n",
      "\n",
      "In [15]: img_1.shape\n",
      "Out[15]: (1276, 2100)\n",
      "\n",
      "In [16]: img_2.shape\n",
      "Out[16]: (1276, 2100)\n",
      "\n",
      "In [17]: len(src)\n",
      "Out[17]: 112\n",
      "\n",
      "In [18]: len(dst)\n",
      "Out[18]: 112\n",
      "\n",
      "In [19]: src[:10]\n",
      "Out[19]: \n",
      "array([[  414.72  ,    47.6928],\n",
      "       [  744.    ,   169.    ],\n",
      "       [ 1093.    ,   108.    ],\n",
      "       [  995.    ,   116.    ],\n",
      "       [  785.    ,   410.    ],\n",
      "       [ 1311.6   ,   171.6   ],\n",
      "       [ 1212.    ,   171.6   ],\n",
      "       [  114.    ,  1225.    ],\n",
      "       [  918.    ,   448.8   ],\n",
      "       [ 1044.    ,   454.8   ]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merges_with_one = [align_images(img_1, x, i) for i, x in enumerate(imgs_blue[10:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i, img in enumerate(merges_with_one):\n",
    "    count = len(merges_with_one)\n",
    "    cols = 3\n",
    "    rows = int(count / cols) + 1\n",
    "    plt.subplot(rows, cols, 1 + i)\n",
    "    plt.imshow(img, aspect='auto')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(merges_with_one[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gels-analysis",
   "language": "python",
   "name": "gels-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
