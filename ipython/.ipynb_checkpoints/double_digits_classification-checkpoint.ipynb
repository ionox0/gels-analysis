{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import scipy\n",
    "import pprint\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "from skimage.feature import hog\n",
    "from skimage.morphology import square, disk\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat\n",
    "from skimage.morphology import black_tophat, skeletonize, convex_hull_image\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from skimage import data\n",
    "import keras\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_things(things, labels):\n",
    "    count = len(things)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    for i, thing in enumerate(things):\n",
    "        cols = 10\n",
    "        rows = int(count / cols) + 1\n",
    "        ax = plt.subplot(rows, cols, 1 + i)\n",
    "        \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title(labels[i])\n",
    "\n",
    "        plt.imshow(thing)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating 2-digit combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "data = mnist.data\n",
    "target = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def random_combination(iterable, r):\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    indices = sorted(random.sample(xrange(n), r))\n",
    "    return tuple(pool[i] for i in indices)\n",
    "\n",
    "def remove_border(img):\n",
    "    where = np.where(img > 0)\n",
    "    y1 = np.min(where[0])\n",
    "    y2 = np.max(where[0])\n",
    "    x1 = np.min(where[1])\n",
    "    x2 = np.max(where[1])\n",
    "    crop = img[y1:y2 , x1:x2]\n",
    "    return crop\n",
    "\n",
    "n_samples = 1000000\n",
    "combs = []\n",
    "combs_labels = []\n",
    "data_w_labels = zip(data, target)\n",
    "random.shuffle(data_w_labels)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    comb = random_combination(data_w_labels, 2)\n",
    "    \n",
    "    first_digit = comb[0][0].reshape((28, 28))\n",
    "    second_digit = comb[1][0].reshape((28, 28))\n",
    "\n",
    "#     thresh = threshold_otsu(first_digit)\n",
    "#     first_digit = (first_digit > thresh).astype(np.uint8)\n",
    "    \n",
    "#     thresh = threshold_otsu(second_digit)\n",
    "#     second_digit = (second_digit > thresh).astype(np.uint8)\n",
    "    \n",
    "    first_mod = remove_border(first_digit)\n",
    "    second_mod = remove_border(second_digit)\n",
    "    \n",
    "    # Make sure height diff is divisible by 2\n",
    "    if not (first_mod.shape[0] % 2 == 0):\n",
    "        first_mod = np.vstack([first_mod, np.zeros((1, first_mod.shape[1]))])\n",
    "    if not (second_mod.shape[0] % 2 == 0):\n",
    "        second_mod = np.vstack([second_mod, np.zeros((1, second_mod.shape[1]))])\n",
    "    \n",
    "    height_diff = first_mod.shape[0] - second_mod.shape[0]\n",
    "    \n",
    "    if height_diff < 0:\n",
    "        padding = int(-height_diff / 2.0)\n",
    "        thepad = np.zeros((padding, first_mod.shape[1]))\n",
    "        first_mod = np.vstack([first_mod, thepad])\n",
    "        first_mod = np.vstack([thepad, first_mod])\n",
    "    elif height_diff > 0:\n",
    "        padding = int(height_diff / 2.0)\n",
    "        thepad = np.zeros((padding, second_mod.shape[1]))\n",
    "        second_mod = np.vstack([second_mod, thepad])\n",
    "        second_mod = np.vstack([thepad, second_mod])\n",
    "    \n",
    "    # Align width\n",
    "    overlap = 1\n",
    "    \n",
    "    height = first_mod.shape[0]\n",
    "    width_1 = first_mod.shape[1]\n",
    "    width_2 = second_mod.shape[1]\n",
    "    \n",
    "    padding = np.zeros((height, width_2 - overlap))\n",
    "    first_mod = np.hstack([first_mod, padding])\n",
    "    padding = np.zeros((height, width_1 - overlap))\n",
    "    second_mod = np.hstack([padding, second_mod])\n",
    "    \n",
    "    overlapped = first_mod.astype(np.uint64) + second_mod.astype(np.uint64)\n",
    "    overlapped = np.clip(overlapped, 0, 255).astype(np.uint8)\n",
    "    padded = np.pad(overlapped, (5, 5), 'constant', constant_values=(0, 0))  \n",
    "    \n",
    "#     binary = (padded > 0).astype(np.uint8)\n",
    "    combs.append(padded)\n",
    "    \n",
    "    label = int(  str(int(comb[0][1])) + str(int(comb[1][1]))  )\n",
    "    combs_labels.append( label )\n",
    "    \n",
    "# combs = np.array(combs)\n",
    "combs_labels = np.array(combs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combs_reshaped = [cv2.resize(x, (38, 28)) for x in combs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combs_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 50\n",
    "plot_things(combs_reshaped[i:i + 50], combs_labels[i:i + 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Extract the features and labels\n",
    "combs_np = np.array(combs_reshaped)\n",
    "features = np.expand_dims(combs_np.reshape(1000000, 28, 38), axis=3)\n",
    "labels = to_categorical(combs_labels)\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28, 38, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 7\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 950000 samples, validate on 50000 samples\n",
      "Epoch 1/7\n",
      "950000/950000 [==============================] - 333s - loss: 0.5841 - acc: 0.8435 - val_loss: 0.0759 - val_acc: 0.9774\n",
      "Epoch 2/7\n",
      "950000/950000 [==============================] - 330s - loss: 0.1171 - acc: 0.9651 - val_loss: 0.0477 - val_acc: 0.9854\n",
      "Epoch 3/7\n",
      "950000/950000 [==============================] - 331s - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0396 - val_acc: 0.9882\n",
      "Epoch 4/7\n",
      "950000/950000 [==============================] - 330s - loss: 0.0631 - acc: 0.9808 - val_loss: 0.0291 - val_acc: 0.9907\n",
      "Epoch 5/7\n",
      "950000/950000 [==============================] - 330s - loss: 0.0523 - acc: 0.9838 - val_loss: 0.0257 - val_acc: 0.9922\n",
      "Epoch 6/7\n",
      "950000/950000 [==============================] - 330s - loss: 0.0450 - acc: 0.9861 - val_loss: 0.0237 - val_acc: 0.9925\n",
      "Epoch 7/7\n",
      "879104/950000 [==========================>...] - ETA: 24s - loss: 0.0397 - acc: 0.9877"
     ]
    }
   ],
   "source": [
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "\n",
    "history_bn = model.fit(\n",
    "    features,\n",
    "    labels,\n",
    "    validation_split=0.05,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[earlyStopping], \n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Save the classifier\n",
    "model.save(filepath='./double_digits_cnn_nonbinary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Gels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf, pp = joblib.load('digits_cls.pkl')\n",
    "model = keras.models.load_model('./double_digits_cnn_nonbinary')\n",
    "model_single = keras.models.load_model('./digits_cnn_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = [1,6,12,21,41,42,51,52,56,83,84,89,90,96,97,106,123,131,136,152,153,156,157] #7, 22\n",
    "filenames = ['../data/gels_nov_2016/Im{} - p. {}.png'.format(i, i) for i in imgs]\n",
    "images = [scipy.misc.imread(f) for f in filenames]\n",
    "\n",
    "april_imgs = [f for f in os.listdir('../data/april_2016_gels_renamed') if not 'tore' in f]\n",
    "april_filenames = ['../data/april_2016_gels_renamed/{}'.format(f) for f in april_imgs]\n",
    "april_images = [scipy.misc.imread(f) for f in april_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sort_rects(rects_ctrs):\n",
    "    rects_sort = sorted(rects_ctrs, key=lambda r: r[0][0])\n",
    "    \n",
    "    result = []\n",
    "    for rect in rects_sort:\n",
    "        if rect[0][3] < 10:\n",
    "            continue\n",
    "\n",
    "        # Filter to only rects with overlap\n",
    "        prev = rect\n",
    "        first = rect\n",
    "        rects_sort_filt = []\n",
    "        rects_sort_filt.append(prev)\n",
    "        for x in rects_sort:\n",
    "            if x == first:\n",
    "                continue\n",
    "            if calc_overlap(x[0], prev[0]) > (prev[0][3] / 3.0) and horiz_dist_ratio_check(prev[0], x[0]):\n",
    "                rects_sort_filt.append(x)\n",
    "                prev = x\n",
    "                \n",
    "        result += rects_sort_filt\n",
    "        for rect_sorted in rects_sort_filt:\n",
    "            rects_sort.remove(rect_sorted)\n",
    "            \n",
    "    return zip(*result)\n",
    "\n",
    "def calc_overlap(rect_1, rect_2):\n",
    "    rect_1_x = rect_1[0]\n",
    "    rect_1_y = rect_1[1]\n",
    "    rect_1_width = rect_1[2]\n",
    "    rect_1_height = rect_1[3]\n",
    "    \n",
    "    rect_2_x = rect_2[0]\n",
    "    rect_2_y = rect_2[1]\n",
    "    rect_2_width = rect_2[2]\n",
    "    rect_2_height = rect_2[3]\n",
    "    \n",
    "    overlap = min(rect_1_y + rect_1_height, rect_2_y + rect_2_height) - max(rect_1_y, rect_2_y)\n",
    "    return overlap\n",
    "\n",
    "def horiz_dist_ratio_check(r1, r2):\n",
    "    return abs(r1[0] + r1[2] - r2[0]) < (3 * r1[2])\n",
    "\n",
    "\n",
    "SZ = 28\n",
    "affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR\n",
    "def deskew(img):\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11'] / m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, (SZ, SZ), flags=affine_flags)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_numbers(\n",
    "    im,\n",
    "    thresh=30,\n",
    "    blue_thresh=False,\n",
    "    blur=0,\n",
    "    contrast_inc=0,\n",
    "    brightness_inc=0,\n",
    "    opening_shape=None,\n",
    "    closing_shape=None,\n",
    "    dilation_size=0,\n",
    "    erosion_size=0,\n",
    "    should_deskew=False):\n",
    "    \n",
    "    im_c = im.copy()\n",
    "    # Convert to grayscale\n",
    "    im_gray = cv2.cvtColor(im_c, cv2.COLOR_BGR2GRAY)\n",
    "    # Just blue channel\n",
    "    im_one = im.copy().astype(np.uint8)[:,:,2]\n",
    "    # Invert the image (todo - use im_gray?)\n",
    "    im_gray = (255 - im_one)\n",
    "    \n",
    "    # Threshold the image (for contours)\n",
    "    if blue_thresh:\n",
    "        # RGB --> BGR (openCV style)\n",
    "        im_bgr = im.copy()[:,:,::-1]\n",
    "        hsv = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2HSV)\n",
    "        # Define range of blue color in HSV\n",
    "        lower_blue = np.array([110,50,50])\n",
    "        upper_blue = np.array([130,255,255])\n",
    "        # Threshold the HSV image to get only blue colors\n",
    "        im_th = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "        im_th = cv2.bitwise_and(im_c, im_c, mask=im_th)\n",
    "        im_th = cv2.cvtColor(im_th, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        ret, im_th = cv2.threshold(im_gray, thresh, 255, cv2.THRESH_BINARY)\n",
    "        im_th = im_th.astype(np.uint8)\n",
    "        \n",
    "    # Opening / Closing (also for contours)\n",
    "    if hasattr(opening_shape, 'shape'):\n",
    "        im_th = opening(im_th, opening_shape)\n",
    "    if hasattr(closing_shape, 'shape'):\n",
    "        im_th = closing(im_th, closing_shape)\n",
    "        \n",
    "    # Gaussian blur\n",
    "    if blur:\n",
    "        im_gray = cv2.medianBlur(im_gray, blur, blur)\n",
    "        \n",
    "    # Brightness\n",
    "    if brightness_inc:\n",
    "        im_expanded = im_gray.astype(np.uint64) + brightness_inc\n",
    "        im_gray = np.clip(im_expanded, 0, 255).astype(np.uint8)\n",
    "    # Contrast\n",
    "    if contrast_inc:\n",
    "        im_expanded = im_gray.astype(np.uint64) * contrast_inc\n",
    "        im_gray = np.clip(im_expanded, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Dilation\n",
    "    if dilation_size:\n",
    "        selem = disk(dilation_size)\n",
    "        im_gray = dilation(im_gray, selem)\n",
    "    # Erosion\n",
    "    if erosion_size:\n",
    "        selem = disk(erosion_size)\n",
    "        im_gray = erosion(im_gray, selem)\n",
    "\n",
    "    # Find Contours\n",
    "    _, ctrs, hierarchy = cv2.findContours(im_th, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Filter based on hierarchy\n",
    "    ctrs = [c for i, c in enumerate(ctrs) if hierarchy[0][i][-1] == -1]\n",
    "    hierarchy = [h for i, h in enumerate(hierarchy[0]) if hierarchy[0][i][-1] == -1]\n",
    "    # Get Contour bounding boxes\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    # Sorted order bounding boxes\n",
    "    sorted_rects, sorted_ctrs = sort_rects(zip(rects, ctrs))\n",
    "    # Remove child rects\n",
    "    ctrs = [c for i, c in enumerate(ctrs) if rects[i][3] > 10]\n",
    "    rects = [r for r in rects if r[3] > 10]\n",
    "    \n",
    "    \n",
    "    # Separate connected digits\n",
    "    for i, rect in enumerate(rects):\n",
    "        x_start = rect[0]\n",
    "        y_start = rect[1]\n",
    "        width = rect[2]\n",
    "        height = rect[3]\n",
    "        \n",
    "        # Skip short artifacts\n",
    "        if height < 10: continue\n",
    "            \n",
    "        im_roi = im_gray[y_start : y_start + height, x_start : x_start + width]\n",
    "        # Draw filled contours (removes overlapping items)\n",
    "        mask = np.zeros((height, width)).astype(np.uint8)\n",
    "        mask = cv2.drawContours(mask, sorted_ctrs, i, (255, 255, 255), cv2.FILLED, offset=(-x_start, -y_start))\n",
    "        roi = cv2.bitwise_and(mask.astype(np.uint8), im_roi.astype(np.uint8)).astype(np.uint8)\n",
    "        \n",
    "        cnt = ctrs[i]\n",
    "        hull = cv2.convexHull(cnt, returnPoints = False)\n",
    "        defects = cv2.convexityDefects(cnt, hull)\n",
    "        \n",
    "        mean_defect_dist = sum([d for s,e,f,d in defects[:,0]]) / defects.shape[0]\n",
    "        large_defects = [(s,e,f,d) for s,e,f,d in defects[:,0] if d > mean_defect_dist]\n",
    "        \n",
    "        roi = np.pad(roi, ((y_start, 0), (x_start, 0)), 'constant', constant_values=(0,0))\n",
    "        for s, e, f, d in large_defects:\n",
    "            dists = [(f[0] - x[0])**2 + (f[1] - x[1])**2 for s, e, x, d in large_defects]\n",
    "            closest_idx = np.argmin(dists)\n",
    "            closest = large_defects[closest_idx]\n",
    "            \n",
    "            start = tuple(cnt[closest[2]][0])\n",
    "            end = tuple(cnt[f][0])\n",
    "            print(roi.shape, start, end, far)\n",
    "            \n",
    "            cv2.line(roi,start,end,[255,255,255],2)\n",
    "            cv2.circle(roi,far,2,[0,0,0],-1)\n",
    "            \n",
    "        plt.imshow(roi)\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    \n",
    "\n",
    "    rois = []\n",
    "    probs = []\n",
    "    date_possibs = []\n",
    "    cur_date_possibs = []\n",
    "    prev_not_one_width = 99999\n",
    "    prev_end_x = sorted_rects[0][0] + sorted_rects[0][2]\n",
    "    prev_end_y = sorted_rects[0][1] + sorted_rects[0][3]\n",
    "    \n",
    "    # For each rectangular region, predict the digit using classifier\n",
    "    for i, rect in enumerate(sorted_rects):\n",
    "        x_start = rect[0]\n",
    "        y_start = rect[1]\n",
    "        width = rect[2]\n",
    "        height = rect[3]\n",
    "\n",
    "        # Skip short artifacts\n",
    "        if height < 10: continue\n",
    "        # Skip long artifacts\n",
    "#         if width > 100: continue\n",
    "\n",
    "        # Try with either im_gray, or im_th_all_colors here\n",
    "        im_roi = im_gray[y_start : y_start + height, x_start : x_start + width]\n",
    "        \n",
    "        # Draw filled contours (removes overlapping items)\n",
    "        mask = np.zeros((height, width)).astype(np.uint8)\n",
    "        mask = cv2.drawContours(mask, sorted_ctrs, i, (255, 255, 255), cv2.FILLED, offset=(-x_start, -y_start))\n",
    "        roi = cv2.bitwise_and(mask.astype(np.uint8), im_roi.astype(np.uint8)).astype(np.uint8)\n",
    "\n",
    "        # Pad ROI to square\n",
    "        if height < width:\n",
    "            padding = int((width - height) / 2.0)\n",
    "            roi = np.pad(roi, ((padding, padding), (0,0)), 'constant', constant_values=(0, 0))\n",
    "        elif width < height:\n",
    "            padding = int((height - width) / 2.0)\n",
    "            roi = np.pad(roi, ((0,0), (padding, padding)), 'constant', constant_values=(0, 0))\n",
    "        roi_pad = np.pad(roi, (5, 5), 'constant', constant_values=(0, 0))\n",
    "        \n",
    "        # Create new date possib (for newlines)\n",
    "        if abs(x_start - prev_end_x) < 80 and abs(y_start - prev_end_y) < 80:\n",
    "            newline = False\n",
    "        else:\n",
    "            newline = True\n",
    "        if newline:\n",
    "            date_possibs += cur_date_possibs\n",
    "            cur_date_possibs = []\n",
    "        \n",
    "        dbl = False\n",
    "        # Differentiate single from connected digits\n",
    "        if width > 1.2 * prev_not_one_width:\n",
    "            dbl = True\n",
    "            roi_resized = cv2.resize(roi_pad, (38 ,28), interpolation=cv2.INTER_NEAREST)\n",
    "            roi_cnn = np.expand_dims(roi_resized, axis=2)\n",
    "\n",
    "            prob = model.predict_proba(np.array([roi_cnn]), verbose=0)\n",
    "            dbl_nbr = np.argmax(prob)\n",
    "                \n",
    "            nbr_prob = prob[0]\n",
    "            \n",
    "            # copy the current possibs\n",
    "            new_cur_date_possibs = copy.deepcopy(cur_date_possibs)\n",
    "            \n",
    "            if len(new_cur_date_possibs) == 0:\n",
    "                new_cur_date_possibs = [[dbl_nbr]]\n",
    "            else:\n",
    "                for date_possib in new_cur_date_possibs:\n",
    "                    date_possib.append(dbl_nbr)\n",
    "                \n",
    "        roi_resized = cv2.resize(roi_pad, (28 ,28), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Deskew\n",
    "        if should_deskew:\n",
    "            roi_resized = deskew(roi_resized)\n",
    "        \n",
    "        roi_cnn = np.expand_dims(roi_resized, axis=2)\n",
    "\n",
    "        prob = model_single.predict_proba(np.array([roi_cnn]), verbose=0)\n",
    "        nbr = np.argmax(prob)\n",
    "        nbr_prob = prob[0]\n",
    "        \n",
    "        if len(cur_date_possibs) == 0:\n",
    "            cur_date_possibs = [[nbr]]\n",
    "        else:\n",
    "            for date_possib in cur_date_possibs:\n",
    "                date_possib.append(nbr)\n",
    "            \n",
    "        if dbl:\n",
    "            cur_date_possibs += new_cur_date_possibs\n",
    "        \n",
    "        prev_end_x = x_start\n",
    "        prev_end_y = y_start\n",
    "\n",
    "        # Mark the roi, label, and hierarchy\n",
    "        cv2.rectangle(im_c, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 100, 255), 1)\n",
    "        cv2.putText(im_c, str(int(nbr)), (rect[0], rect[1]), cv2.FONT_ITALIC, 0.4, (255, 0, 100), 1)\n",
    "#         cv2.putText(im_c, str(hierarchy[0][i]) + str(int(nbr)), (rect[0], rect[1] - (250 - i*20)), cv2.FONT_ITALIC, 0.4, (randint(0,255), 0, 255), 1)\n",
    "        \n",
    "        if dbl:\n",
    "            dbl_label = str(int(dbl_nbr))\n",
    "            cv2.putText(im_c, dbl_label, (rect[0], rect[1] - 15), cv2.FONT_ITALIC, 0.3, (255, 0, 200), 1)\n",
    "            \n",
    "        probs.append(0)\n",
    "        rois.append(roi_resized)\n",
    "        \n",
    "        if nbr != 1:\n",
    "            prev_not_one_width = width\n",
    "       \n",
    "    # Append the final date possibility\n",
    "    date_possibs += cur_date_possibs\n",
    "    \n",
    "    return im_c, rois, date_possibs, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here1\n",
      "Python 2.7.10 (default, Jul 13 2015, 12:05:58) \n",
      "Type \"copyright\", \"credits\" or \"license\" for more information.\n",
      "\n",
      "IPython 5.1.0 -- An enhanced Interactive Python.\n",
      "?         -> Introduction and overview of IPython's features.\n",
      "%quickref -> Quick reference.\n",
      "help      -> Python's own help system.\n",
      "object?   -> Details about 'object', use 'object??' for extra details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# images[13][0:790,0:1000] = [255, 255, 255]\n",
    "\n",
    "im_labeled, rois, date_possibs, probs = extract_numbers(\n",
    "#     images[16][650:780,800:],\n",
    "#     images[3][700:880,490:1000],\n",
    "    april_images[33][2000:,100:],\n",
    "    thresh=80,\n",
    "#     blue_thresh=True,\n",
    "#     blur=5,\n",
    "    brightness_inc=50,\n",
    "#     contrast_inc=1.5,\n",
    "    opening_shape=disk(5),\n",
    "#     closing_shape=disk(5),\n",
    "#     dilation_size=2,\n",
    "#     erosion_size=3,\n",
    "    should_deskew=True\n",
    ")\n",
    "\n",
    "plt.imshow(im_labeled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_things(rois, range(len(rois)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in date_possibs:\n",
    "    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
